{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ConsoleDot service in Go This projects aims to cover all basic concepts needed for development of service for console.redhat.com. It aims to be a basic API serving service with a database. Repository structure All packages live under /internal to denote we do not intend to share these with other apps. All binaries have a directory under /cmd these are the app entrypoints.","title":"Home"},{"location":"#consoledot-service-in-go","text":"This projects aims to cover all basic concepts needed for development of service for console.redhat.com. It aims to be a basic API serving service with a database.","title":"ConsoleDot service in Go"},{"location":"#repository-structure","text":"All packages live under /internal to denote we do not intend to share these with other apps. All binaries have a directory under /cmd these are the app entrypoints.","title":"Repository structure"},{"location":"concepts/01-documentation/","text":"Documentation for your project This is a bit meta you say, sure it is! :) We believe starting with documentation is important, so you don't need to catch up later. Architecture Start with simple architecture of your project. You've sure brainstormed it before starting, just put in the docs folder what you have! Diagrams can be plain png s of course, but if you want to start with something better, do it with PlantUML. It helps you keep it up to date, because you keep the source code of the diagram with the code. Architecture Decision Records These Markdown documents are meant to document major decisions you've taken during your project development. Changing decisions is easy with a follow-up ADR, but you get an awesome benefit of the track record for the decisions. That's very helpful for every new developer, like you after few months working on something else ;) See more for example at adr.GitHub.io","title":"Documentation"},{"location":"concepts/01-documentation/#documentation-for-your-project","text":"This is a bit meta you say, sure it is! :) We believe starting with documentation is important, so you don't need to catch up later.","title":"Documentation for your project"},{"location":"concepts/01-documentation/#architecture","text":"Start with simple architecture of your project. You've sure brainstormed it before starting, just put in the docs folder what you have! Diagrams can be plain png s of course, but if you want to start with something better, do it with PlantUML. It helps you keep it up to date, because you keep the source code of the diagram with the code.","title":"Architecture"},{"location":"concepts/01-documentation/#architecture-decision-records","text":"These Markdown documents are meant to document major decisions you've taken during your project development. Changing decisions is easy with a follow-up ADR, but you get an awesome benefit of the track record for the decisions. That's very helpful for every new developer, like you after few months working on something else ;) See more for example at adr.GitHub.io","title":"Architecture Decision Records"},{"location":"concepts/02-makefile/","text":"Makefile Golan has a tooling around many commands. We believe it is helpful to customize these commands for actual project needs. We help document all the current targets by providing the make help we encourage you to continue this effort. It makes it very easy for new developers to see what common actions are needed for working on the project. We drafted the Makefile targets split under mk directory, so it's easier to keep targets grouped by their purpose.","title":"Makefile"},{"location":"concepts/02-makefile/#makefile","text":"Golan has a tooling around many commands. We believe it is helpful to customize these commands for actual project needs. We help document all the current targets by providing the make help we encourage you to continue this effort. It makes it very easy for new developers to see what common actions are needed for working on the project. We drafted the Makefile targets split under mk directory, so it's easier to keep targets grouped by their purpose.","title":"Makefile"},{"location":"concepts/03-building/","text":"Building your project Exciting! We are getting somewhere :) You can run your app by: make run And you can build a container for it locally by: make build-podman Following information is all about what happens when you run these commands :) Go dependencies We have three make targets for working with dependencies: make download-deps installs dependencies locally (aliased make prep ) make update-deps updates dependencies to the newest versions make tidy-deps cleans up dependencies locally The binary The main binary is called api and it serves as api application http server for our service. It's entry point is cmd/api/main.go Containerization Your app will run in the production environment in Container in OpenShift. So lets package our app in a Container :) You can build the container with Podman by running make build-podman . There are two phases in the build. It is captured in Containerfile . First is the build phase. We use the official Red Hat go-toolset build container to build our projects. We have manually set the go version of the container, when bumping the go version, it needs to be bumped here. The build itself is done by copying all project files in /build directory in the build container. Followed by running make prep build strip which runs phases: Install dependencies Building binaries Stripping binaries of debug information (to keep them smaller). FROM registry.access.redhat.com/ubi8/go-toolset:1:18 as build USER 0 RUN mkdir /build WORKDIR /build COPY . . RUN make prep build strip Second phase produces the final container image It just copies the binaries from the build container. FROM registry.access.redhat.com/ubi8/ubi-minimal:latest COPY --from=build /build/api /api USER 1001 CMD [\"/api\"] We are done :)","title":"Building"},{"location":"concepts/03-building/#building-your-project","text":"Exciting! We are getting somewhere :) You can run your app by: make run And you can build a container for it locally by: make build-podman Following information is all about what happens when you run these commands :)","title":"Building your project"},{"location":"concepts/03-building/#go-dependencies","text":"We have three make targets for working with dependencies: make download-deps installs dependencies locally (aliased make prep ) make update-deps updates dependencies to the newest versions make tidy-deps cleans up dependencies locally","title":"Go dependencies"},{"location":"concepts/03-building/#the-binary","text":"The main binary is called api and it serves as api application http server for our service. It's entry point is cmd/api/main.go","title":"The binary"},{"location":"concepts/03-building/#containerization","text":"Your app will run in the production environment in Container in OpenShift. So lets package our app in a Container :) You can build the container with Podman by running make build-podman . There are two phases in the build. It is captured in Containerfile .","title":"Containerization"},{"location":"concepts/03-building/#first-is-the-build-phase","text":"We use the official Red Hat go-toolset build container to build our projects. We have manually set the go version of the container, when bumping the go version, it needs to be bumped here. The build itself is done by copying all project files in /build directory in the build container. Followed by running make prep build strip which runs phases: Install dependencies Building binaries Stripping binaries of debug information (to keep them smaller). FROM registry.access.redhat.com/ubi8/go-toolset:1:18 as build USER 0 RUN mkdir /build WORKDIR /build COPY . . RUN make prep build strip","title":"First is the build phase."},{"location":"concepts/03-building/#second-phase-produces-the-final-container-image","text":"It just copies the binaries from the build container. FROM registry.access.redhat.com/ubi8/ubi-minimal:latest COPY --from=build /build/api /api USER 1001 CMD [\"/api\"] We are done :)","title":"Second phase produces the final container image"},{"location":"concepts/04-routing/","text":"HTTP Routing Here we are diving into the implementation of the service itself. For routing this service template uses go-chi library, as it is the most lightweight, but still does all we need. You can of course choose a different one if you like and the concepts will be very similar. We will place all relevant routing code under /internal/routes . Here we will not talk about metrics router, that is covered in Metrics Concept. Root router The entry point to the routing is routes.RootRouter() this sets up the root path router. This is / path on our server. This service uses this path for Liveness and Readiness probes of k8s. We will get to this later. For now the important part is that within this router we mount another API router onto a prefixed path. API router Our service will coexist with other services behind a shared public gateway. The gateway routes traffic by route prefix, but does not strip the matched prefix. So if our service will match for traffic on /api/template prefix, the full path gets forwarded. This means all our public facing paths need to be exposed with this prefix. The prefix is determined by routes.PathPrefix function. Individual routes All routes have their matching pattern and a http.HandlerFunc . Handler function is a function that receives a request as a parameter and writes response in a specialized IO. Our use of handlers is basically Controller from an MVC apps. We will put all our handlers in a /internal/services folder, more on that later. Chi routes are defined by calling function named by their matching HTTP verb. For example router.Get(\"/hello\", Handler) creates a GET route for pattern /hello . Grouping routes We can group routes under one prefix and only define the suffix for them. To define the route with a prefix we would do following. router.Route(\"/prefix\", func(subRouter chi.Router) { subRouter.Get(\"/hello\", Handler) }) HTTP server To put this all together, we will put following code in our api entry point and start a http server. // cmd/api/main.go rootRouter := routes.RootRouter() apiServer := http.Server{ Addr: fmt.Sprintf(\":%d\", 8000), Handler: rootRouter, } Later we will make this port configurable. Start listening Following code starts up the server we've set up. It will write out error message unless the server has been stopped gracefully. if err := apiServer.ListenAndServe(); err != nil { if !errors.Is(err, http.ErrServerClosed) { log.Fatal().Err(err).Msg(\"Main service listen error\") } } Stop listening Here we will cover graceful shutdown of our server. We won't cover all the details of following code. We set up a channel that will get notified when we receive SIGINT or SIGTERM . The signal wait is blocking, so we are waiting for it in separate goroutine. We have another channel that we wait for in our main and once this gets triggered, we finish.","title":"Routing"},{"location":"concepts/04-routing/#http-routing","text":"Here we are diving into the implementation of the service itself. For routing this service template uses go-chi library, as it is the most lightweight, but still does all we need. You can of course choose a different one if you like and the concepts will be very similar. We will place all relevant routing code under /internal/routes . Here we will not talk about metrics router, that is covered in Metrics Concept.","title":"HTTP Routing"},{"location":"concepts/04-routing/#root-router","text":"The entry point to the routing is routes.RootRouter() this sets up the root path router. This is / path on our server. This service uses this path for Liveness and Readiness probes of k8s. We will get to this later. For now the important part is that within this router we mount another API router onto a prefixed path.","title":"Root router"},{"location":"concepts/04-routing/#api-router","text":"Our service will coexist with other services behind a shared public gateway. The gateway routes traffic by route prefix, but does not strip the matched prefix. So if our service will match for traffic on /api/template prefix, the full path gets forwarded. This means all our public facing paths need to be exposed with this prefix. The prefix is determined by routes.PathPrefix function.","title":"API router"},{"location":"concepts/04-routing/#individual-routes","text":"All routes have their matching pattern and a http.HandlerFunc . Handler function is a function that receives a request as a parameter and writes response in a specialized IO. Our use of handlers is basically Controller from an MVC apps. We will put all our handlers in a /internal/services folder, more on that later. Chi routes are defined by calling function named by their matching HTTP verb. For example router.Get(\"/hello\", Handler) creates a GET route for pattern /hello .","title":"Individual routes"},{"location":"concepts/04-routing/#grouping-routes","text":"We can group routes under one prefix and only define the suffix for them. To define the route with a prefix we would do following. router.Route(\"/prefix\", func(subRouter chi.Router) { subRouter.Get(\"/hello\", Handler) })","title":"Grouping routes"},{"location":"concepts/04-routing/#http-server","text":"To put this all together, we will put following code in our api entry point and start a http server. // cmd/api/main.go rootRouter := routes.RootRouter() apiServer := http.Server{ Addr: fmt.Sprintf(\":%d\", 8000), Handler: rootRouter, } Later we will make this port configurable.","title":"HTTP server"},{"location":"concepts/04-routing/#start-listening","text":"Following code starts up the server we've set up. It will write out error message unless the server has been stopped gracefully. if err := apiServer.ListenAndServe(); err != nil { if !errors.Is(err, http.ErrServerClosed) { log.Fatal().Err(err).Msg(\"Main service listen error\") } }","title":"Start listening"},{"location":"concepts/04-routing/#stop-listening","text":"Here we will cover graceful shutdown of our server. We won't cover all the details of following code. We set up a channel that will get notified when we receive SIGINT or SIGTERM . The signal wait is blocking, so we are waiting for it in separate goroutine. We have another channel that we wait for in our main and once this gets triggered, we finish.","title":"Stop listening"},{"location":"concepts/05-logging/","text":"Logging This template introduces zerolog over platform recommended logrus . Until this is interchangeable Authors feel like zerolog is faster, easier to set up and use and has smaller memory footprint. The global logger is set up at the start of our service. For every request we will set up a new context logger and store it into a request context. We use a logging middleware to do this. This approach makes it easy to add additional fields and these are passed to all log entries. Context should be kept very small as it gets passed very often through the whole stack. Zerolog has such a small footprint that this is ok to do. This approach standardize logging into a pattern of fetching logger from context and logging with help of this logger. Every function can then be called in any context. We are always sure it logs correct log identifiers. Log output - cloudwatch We need to set up logging output. The template has two outputs. Stdout writer used for development and for CI pipelines is very easy to initialize. stdWriter := zerolog.ConsoleWriter{ Out: os.Stdout, TimeFormat: time.Kitchen, } Second for production logging. In production, we are logging to Amazon Cloudwatch. From Cloudwatch, the platform team automatically pulls the logs to our Kibana. The service responsibility is only to deliver logs to Cloudwatch. To set up Cloudwatch writer, in our logging.InitializeLogger function, we need Cloudwatch credentials, we will get to that in next chapter. Following snippet initializes Cloudwatch writer assuming the credentials variables. func newCloudwatchWriter(region string, key string, secret string, session string, logGroup string, logStream string) (*io.Writer, error) { cache := aws.NewCredentialsCache(credentials.NewStaticCredentialsProvider(key, secret, session)) cwClient := cloudwatchlogs.New(cloudwatchlogs.Options{ Region: region, Credentials: cache, }) cloudWatchWriter, err := cloudwatchwriter2.NewWithClient(cwClient, 500*time.Millisecond, logGroup, logStream) return cloudWatchWriter, err } Now when we will be ready to decide whether we want to use Cloudwatch or Stdout, we are ready to use the following to initialize our logger. zerolog.SetGlobalLevel(level) //nolint:reassign zerolog.ErrorStackMarshaler = pkgerrors.MarshalStack output := initializeLogOutput() // here we will need to decide on the output used. logger := zerolog.New(output) // decorate logger (and thus every log line) with hostname and timestamp logger = logger.With().Timestamp().Str(\"hostname\", hostname).Logger() Log middleware Middleware in Golang is a function that takes next http.Handler as parameter and returns http.Handler itself. The inner http.Handler needs to call next.ServeHTTP() to invoke the following handler. The simplest middleware is a function, that is called on ServeHTTP() , go provides a helper http.HandlerFunc to create such a function We further wrap that with a higher order function that allows us to pass logger. In case we want to change logger we want to use, it would be easier to do then if the middleware would use the global logger directly. The middleware enhances the global (passed in) logger with the request context fields like remote IP, request path, HTTP method. Then we log the very first line of every request. loggerCtx := globalLogger.With(). Str(\"remote_ip\", r.RemoteAddr). Str(\"url\", r.URL.Path). Str(\"method\", r.Method) contextLogger := loggerCtx.Logger() contextLogger.Debug().Msgf(\"Started %s request %s\", r.Method, r.URL.Path) The major thing we do here is to store our logger into the context that we pass down the middleware stack. // see logging.WithLogger() ctx := WithLogger(r.Context(), &contextLogger) next.ServeHTTP(ww, r.WithContext(ctx)) We follow up with deferring a function to log last log line of every request. We run it deferred, effectively after all following middlewares and thus at the end of the request. This function has one very special effect, it recovers from panic and logs it. Every panic that happens further down the middleware stack is thus recovered and logged in our middleware. t1 := time.Now() defer func() { duration := time.Since(t1) afterLogger := contextLogger.With(). Dur(\"latency_ms\", duration). Int(\"bytes_in\", bytesIn). Int(\"bytes_out\", ww.BytesWritten()). Logger() // prevent the application from exiting if rec := recover(); rec != nil { afterLogger.Error(). Bool(\"panic\", true). Int(\"status\", http.StatusInternalServerError). Msgf(\"Unhandled panic: %s\\n%s\", rec, debug.Stack()) http.Error(w, http.StatusText(http.StatusInternalServerError), http.StatusInternalServerError) } log.Info(). Int(\"status\", ww.Status()). Msgf(\"Completed %s request %s in %s with %d\", r.Method, r.URL.Path, duration.Round(time.Millisecond).String(), ww.Status()) }() Add middleware to stack Now the last thing we need to do is to add our middleware to the API router. // internal/routes/api_router.go router.Use(logging.NewMiddleware(log.Logger)) And we are all setup. Using the logger Now we have the logger in the context, we will be passing context through the app. To use the logger, we will do following. logger := logging.Logger(ctx) logger.Info().Msg(\"Message one.\") logger.Debug().Msg(\"Message two.\") Happy logging! :)","title":"Logging"},{"location":"concepts/05-logging/#logging","text":"This template introduces zerolog over platform recommended logrus . Until this is interchangeable Authors feel like zerolog is faster, easier to set up and use and has smaller memory footprint. The global logger is set up at the start of our service. For every request we will set up a new context logger and store it into a request context. We use a logging middleware to do this. This approach makes it easy to add additional fields and these are passed to all log entries. Context should be kept very small as it gets passed very often through the whole stack. Zerolog has such a small footprint that this is ok to do. This approach standardize logging into a pattern of fetching logger from context and logging with help of this logger. Every function can then be called in any context. We are always sure it logs correct log identifiers.","title":"Logging"},{"location":"concepts/05-logging/#log-output-cloudwatch","text":"We need to set up logging output. The template has two outputs. Stdout writer used for development and for CI pipelines is very easy to initialize. stdWriter := zerolog.ConsoleWriter{ Out: os.Stdout, TimeFormat: time.Kitchen, } Second for production logging. In production, we are logging to Amazon Cloudwatch. From Cloudwatch, the platform team automatically pulls the logs to our Kibana. The service responsibility is only to deliver logs to Cloudwatch. To set up Cloudwatch writer, in our logging.InitializeLogger function, we need Cloudwatch credentials, we will get to that in next chapter. Following snippet initializes Cloudwatch writer assuming the credentials variables. func newCloudwatchWriter(region string, key string, secret string, session string, logGroup string, logStream string) (*io.Writer, error) { cache := aws.NewCredentialsCache(credentials.NewStaticCredentialsProvider(key, secret, session)) cwClient := cloudwatchlogs.New(cloudwatchlogs.Options{ Region: region, Credentials: cache, }) cloudWatchWriter, err := cloudwatchwriter2.NewWithClient(cwClient, 500*time.Millisecond, logGroup, logStream) return cloudWatchWriter, err } Now when we will be ready to decide whether we want to use Cloudwatch or Stdout, we are ready to use the following to initialize our logger. zerolog.SetGlobalLevel(level) //nolint:reassign zerolog.ErrorStackMarshaler = pkgerrors.MarshalStack output := initializeLogOutput() // here we will need to decide on the output used. logger := zerolog.New(output) // decorate logger (and thus every log line) with hostname and timestamp logger = logger.With().Timestamp().Str(\"hostname\", hostname).Logger()","title":"Log output - cloudwatch"},{"location":"concepts/05-logging/#log-middleware","text":"Middleware in Golang is a function that takes next http.Handler as parameter and returns http.Handler itself. The inner http.Handler needs to call next.ServeHTTP() to invoke the following handler. The simplest middleware is a function, that is called on ServeHTTP() , go provides a helper http.HandlerFunc to create such a function We further wrap that with a higher order function that allows us to pass logger. In case we want to change logger we want to use, it would be easier to do then if the middleware would use the global logger directly. The middleware enhances the global (passed in) logger with the request context fields like remote IP, request path, HTTP method. Then we log the very first line of every request. loggerCtx := globalLogger.With(). Str(\"remote_ip\", r.RemoteAddr). Str(\"url\", r.URL.Path). Str(\"method\", r.Method) contextLogger := loggerCtx.Logger() contextLogger.Debug().Msgf(\"Started %s request %s\", r.Method, r.URL.Path) The major thing we do here is to store our logger into the context that we pass down the middleware stack. // see logging.WithLogger() ctx := WithLogger(r.Context(), &contextLogger) next.ServeHTTP(ww, r.WithContext(ctx)) We follow up with deferring a function to log last log line of every request. We run it deferred, effectively after all following middlewares and thus at the end of the request. This function has one very special effect, it recovers from panic and logs it. Every panic that happens further down the middleware stack is thus recovered and logged in our middleware. t1 := time.Now() defer func() { duration := time.Since(t1) afterLogger := contextLogger.With(). Dur(\"latency_ms\", duration). Int(\"bytes_in\", bytesIn). Int(\"bytes_out\", ww.BytesWritten()). Logger() // prevent the application from exiting if rec := recover(); rec != nil { afterLogger.Error(). Bool(\"panic\", true). Int(\"status\", http.StatusInternalServerError). Msgf(\"Unhandled panic: %s\\n%s\", rec, debug.Stack()) http.Error(w, http.StatusText(http.StatusInternalServerError), http.StatusInternalServerError) } log.Info(). Int(\"status\", ww.Status()). Msgf(\"Completed %s request %s in %s with %d\", r.Method, r.URL.Path, duration.Round(time.Millisecond).String(), ww.Status()) }()","title":"Log middleware"},{"location":"concepts/05-logging/#add-middleware-to-stack","text":"Now the last thing we need to do is to add our middleware to the API router. // internal/routes/api_router.go router.Use(logging.NewMiddleware(log.Logger)) And we are all setup.","title":"Add middleware to stack"},{"location":"concepts/05-logging/#using-the-logger","text":"Now we have the logger in the context, we will be passing context through the app. To use the logger, we will do following. logger := logging.Logger(ctx) logger.Info().Msg(\"Message one.\") logger.Debug().Msg(\"Message two.\") Happy logging! :)","title":"Using the logger"},{"location":"concepts/06-configuration/","text":"Configuration and clowder To customize our app across environments we need some configuration. In addition to standard application configuration we need to consume configuration from Red Hat Insights deployer clowder . Basic configuration We define structure config in internal/config/config.go to hold all our configuration variables. We have nested structures grouping configuration variables by category. We export these categories by referencing them by exported variables on package level Category = &config.Category . Container application configuration is mostly based on environment variables. We want to have all our environments close. We load all configuration from environment variables. To configure our app locally for development and unit testing, we will use .env files that stay close production setup. To make this easy locally, we provide example configuration, that can be regenerated by make generate-example-config . To load configuration just run Initialize with the .env file as parameter. In the container this file does not exist and Initialize method will load config from environment. config.Initialize(\"config/api.env\") Clowder We will touch Clowder more during deployments as it is mainly a deployer operator. But as a deployer it wraps up many integrations to other services in production environments. Most notably for now it holds configurations of Database and Cloudwatch. Clowder adds these in a file in a container layer. There is a shared ConsoleDot library that loads this file for you and parses the config into go struct. Following snippet overrides Database and Cloudwatch config with Clowder provided config. import clowder \"github.com/redhatinsights/app-common-go/pkg/api/v1\" if clowder.IsClowderEnabled() { cfg := clowder.LoadedConfig // database config.Database.Host = cfg.Database.Hostname config.Database.Port = uint16(cfg.Database.Port) config.Database.User = cfg.Database.Username config.Database.Password = cfg.Database.Password config.Database.Name = cfg.Database.Name // cloudwatch (is blank in ephemeral) cw := cfg.Logging.Cloudwatch if cw.Region != \"\" && cw.AccessKeyId != \"\" && cw.SecretAccessKey != \"\" && cw.LogGroup != \"\" { config.Cloudwatch.Enabled = true config.Cloudwatch.Key = cw.AccessKeyId config.Cloudwatch.Secret = cw.SecretAccessKey config.Cloudwatch.Region = cw.Region config.Cloudwatch.Group = cw.LogGroup } } Use it :) Now the config package holds all your configuration at the fingertip. You can access it anywhere from your app by config.Category.value . Remember the hardcoded http port? Now we can use config.Application.Port to configure it! :)","title":"Configuration"},{"location":"concepts/06-configuration/#configuration-and-clowder","text":"To customize our app across environments we need some configuration. In addition to standard application configuration we need to consume configuration from Red Hat Insights deployer clowder .","title":"Configuration and clowder"},{"location":"concepts/06-configuration/#basic-configuration","text":"We define structure config in internal/config/config.go to hold all our configuration variables. We have nested structures grouping configuration variables by category. We export these categories by referencing them by exported variables on package level Category = &config.Category . Container application configuration is mostly based on environment variables. We want to have all our environments close. We load all configuration from environment variables. To configure our app locally for development and unit testing, we will use .env files that stay close production setup. To make this easy locally, we provide example configuration, that can be regenerated by make generate-example-config . To load configuration just run Initialize with the .env file as parameter. In the container this file does not exist and Initialize method will load config from environment. config.Initialize(\"config/api.env\")","title":"Basic configuration"},{"location":"concepts/06-configuration/#clowder","text":"We will touch Clowder more during deployments as it is mainly a deployer operator. But as a deployer it wraps up many integrations to other services in production environments. Most notably for now it holds configurations of Database and Cloudwatch. Clowder adds these in a file in a container layer. There is a shared ConsoleDot library that loads this file for you and parses the config into go struct. Following snippet overrides Database and Cloudwatch config with Clowder provided config. import clowder \"github.com/redhatinsights/app-common-go/pkg/api/v1\" if clowder.IsClowderEnabled() { cfg := clowder.LoadedConfig // database config.Database.Host = cfg.Database.Hostname config.Database.Port = uint16(cfg.Database.Port) config.Database.User = cfg.Database.Username config.Database.Password = cfg.Database.Password config.Database.Name = cfg.Database.Name // cloudwatch (is blank in ephemeral) cw := cfg.Logging.Cloudwatch if cw.Region != \"\" && cw.AccessKeyId != \"\" && cw.SecretAccessKey != \"\" && cw.LogGroup != \"\" { config.Cloudwatch.Enabled = true config.Cloudwatch.Key = cw.AccessKeyId config.Cloudwatch.Secret = cw.SecretAccessKey config.Cloudwatch.Region = cw.Region config.Cloudwatch.Group = cw.LogGroup } }","title":"Clowder"},{"location":"concepts/06-configuration/#use-it","text":"Now the config package holds all your configuration at the fingertip. You can access it anywhere from your app by config.Category.value . Remember the hardcoded http port? Now we can use config.Application.Port to configure it! :)","title":"Use it :)"},{"location":"concepts/07-database/","text":"Database When we want to keep state, we most likely want a relational database for our service. ConsoleDot platform has settled on using PostgreSQL for all apps. This give apps clear choice for drivers, we can build our service with only single database in mind. When building a go application we could use GORM that deals with any database and has many ORM features. In this service tho, we expect to the database model being quite simple and use low level drivers. This gives us much more power to use pure go objects and strong typing. Migrations We use simple tool tern for migrations and migrations written in pure SQL. It allows to lock database during migrations. We use go embedding for migrations, so migrations are embedded into the migration binary. Code structure DB package We keep database initialization in a separate package. Here we just initialize the database connection global pool that can be accessed from other packages. Initialization db.Initialize accepts schema, we will use this for integration testing later on. DAO To organize our code, we want some structure and this service uses Data access objects. These are objects that abstract the data fetching process and define data access interfaces. This allows for easy database abstraction. We can use this during unit testing, to stub away database. Model Model is simple data structure that represents an entity of state. DAO methods Example dao method, that accepts a model and saves it in a database. func (x *helloDaoPgx) RecordHello(ctx context.Context, hello *models.Hello) error { query := ` INSERT INTO hellos (from, to, message) VALUES ($1, $2, $3) RETURNING id` err := db.Pool.QueryRow(ctx, query, hello.From, hello.To, hello.Message).Scan(&hello.ID) if err != nil { return fmt.Errorf(\"pgx error: %w\", err) } return nil }","title":"Database"},{"location":"concepts/07-database/#database","text":"When we want to keep state, we most likely want a relational database for our service. ConsoleDot platform has settled on using PostgreSQL for all apps. This give apps clear choice for drivers, we can build our service with only single database in mind. When building a go application we could use GORM that deals with any database and has many ORM features. In this service tho, we expect to the database model being quite simple and use low level drivers. This gives us much more power to use pure go objects and strong typing.","title":"Database"},{"location":"concepts/07-database/#migrations","text":"We use simple tool tern for migrations and migrations written in pure SQL. It allows to lock database during migrations. We use go embedding for migrations, so migrations are embedded into the migration binary.","title":"Migrations"},{"location":"concepts/07-database/#code-structure","text":"","title":"Code structure"},{"location":"concepts/07-database/#db-package","text":"We keep database initialization in a separate package. Here we just initialize the database connection global pool that can be accessed from other packages. Initialization db.Initialize accepts schema, we will use this for integration testing later on.","title":"DB package"},{"location":"concepts/07-database/#dao","text":"To organize our code, we want some structure and this service uses Data access objects. These are objects that abstract the data fetching process and define data access interfaces. This allows for easy database abstraction. We can use this during unit testing, to stub away database.","title":"DAO"},{"location":"concepts/07-database/#model","text":"Model is simple data structure that represents an entity of state.","title":"Model"},{"location":"concepts/07-database/#dao-methods","text":"Example dao method, that accepts a model and saves it in a database. func (x *helloDaoPgx) RecordHello(ctx context.Context, hello *models.Hello) error { query := ` INSERT INTO hellos (from, to, message) VALUES ($1, $2, $3) RETURNING id` err := db.Pool.QueryRow(ctx, query, hello.From, hello.To, hello.Message).Scan(&hello.ID) if err != nil { return fmt.Errorf(\"pgx error: %w\", err) } return nil }","title":"DAO methods"}]}